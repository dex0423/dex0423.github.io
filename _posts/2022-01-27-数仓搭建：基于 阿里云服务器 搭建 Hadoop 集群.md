---
layout:     post
title:      数仓搭建：基于 阿里云服务器 搭建 Hadoop 集群
subtitle:
date:       2022-01-27
author:     dex0423
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - 数仓
---

# 1. 环境准备

##### 1.1. 配置主机映射

- 设置服务器的映射关系，在三台服务器依次操作。

  ```aidl
  vi /etc/hosts
  ```

  ```aidl
  172.xxx.xxx.xxx   hadoop102 
  172.xxx.xxx.xxx   hadoop104
  172.xxx.xxx.xxx   hadoop103
  ```

##### 1.2. 配置免密登录

- 生成 ssh 秘钥并复制。

  ```
  cd ~/.ssh/
  
  ssh-keygen -t rsa
  
  ssh-copy-id hadoop102
  ssh-copy-id hadoop103
  ssh-copy-id hadoop104
  ```

##### 1.3. 创建文件分发脚本

- 在 bin 目录下创建 xsync；

    ```aidl
    cd /bin & vim xsync
    ```

- 编辑脚本；

    ```aidl
    #!/bin/sh
    
    # 获取输入参数个数，如果没有参数，直接退出
    pcount=$#
    if((pcount!=4)); then
        echo Usage: $0 filename servername startno endno
        exit;
    fi
    
    
    # 获取文件名称
    p1=$1
    fname=`basename $p1`
    echo fname=$fname
    
    # 获取上级目录到绝对路径
    pdir=`cd -P $(dirname $p1); pwd`
    echo pdir=$pdir
    # 获取当前用户名称
    user=`whoami`
    # 获取hostname及起止号
    slave=$2
    startline=$3
    endline=$4
    
    # 循环
    for((host=$startline; host<=$endline; host++)); do
        echo $pdir/$fname $user@$slave$host:$pdir
        echo ==================$slave$host==================
        rsync -rvl $pdir/$fname $user@$slave$host:$pdir
    done
    ```

- 修改权限

    ```aidl
    chmod 777 xsync
    ```

##### 1.4. 安装 JDK

- 上传文件
  - 上传 `jdk-8u162-linux-x64.tar.gz` 到 hadoop102 服务器 `/opt/software` 目录下；
- 解压安装

  ```aidl
  tar -zxvf jdk-8u162-linux-x64.tar.gz -C /opt/module/
  
  mv /opt/module/jdk1.8.0_162/ /usr/local/jdk1.8
  ```
- 分发 jdk 
  ```aidl
  xsync /usr/local/jdk1.8/
  ```
- 添加环境变量
  ```
  sudo vi /etc/profile
  
  # 在文件末尾添加 PATH 路径
  export JAVA_HOME=/usr/local/jdk1.8
  export PATH=$PATH:$JAVA_HOME/bin
  ```
- 分发 `/etc/profile`
  ```
  xsync /etc/profile
  ```
- 在三台服务器上，依次启用环境变量
  ```
  source /etc/profile
  ```
- 检查 jdk
  ```
  java  -version
  ```

  

# 2. 安装 Hadoop

##### 2.1. 安装

- 上传文件
  - 上传文件 `hadoop-3.1.3.tar.gz` 到 hadoop102 服务器 `/opt/software` 目录
- 解压安装
  ```
  tar -vxf hadoop-3.1.3.tar.gz -C /opt/module/
  
  mv /opt/module/hadoop-3.1.3/ /usr/local/hadoop-3.1.3
  ```
- 分发 hadoop 文件
  ```
  xsync /usr/local/hadoop-3.1.3/
  ```

##### 2.2. 添加环境变量

- 添加环境变量
  ```
  export HADOOP_HOME=/usr/local/hadoop-3.1.3
  export PATH=$PATH:$HADOOP_HOME/bin
  export PATH=$PATH:$HADOOP_HOME/sbin
  export HADOOP_INSTALL=$HADOOP_HOME
  export HADOOP_MAPRED_HOME=$HADOOP_HOME
  export HADOOP_COMMON_HOME=$HADOOP_HOME
  export HADOOP_HDFS_HOME=$HADOOP_HOME
  export YARN_HOME=$HADOOP_HOME
  export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
  ```

- 分发 `/etc/profile`
  ```
  xsync /etc/profile
  ```

- 在三台服务器上，依次启用环境变量
  ```
  source /etc/profile
  ```
  
- 检查安装情况
  ```
  hadoop version
  ```
  
- 查看 Hadoop 目录结构
  ```aidl
  cd $HADOOP_HOME
  ll
  
  drwxr-xr-x 2 root root   4096 May  8 22:04 bin
  drwxr-xr-x 3 root root   4096 May  8 22:04 etc
  drwxr-xr-x 2 root root   4096 May  8 22:04 include
  drwxr-xr-x 3 root root   4096 May  8 22:04 lib
  drwxr-xr-x 4 root root   4096 May  8 22:04 libexec
  -rw-r--r-- 1 root root 147145 May  8 22:04 LICENSE.txt
  -rw-r--r-- 1 root root  21867 May  8 22:04 NOTICE.txt
  -rw-r--r-- 1 root root   1366 May  8 22:04 README.txt
  drwxr-xr-x 3 root root   4096 May  8 22:04 sbin
  drwxr-xr-x 4 root root   4096 May  8 22:04 share
  ```

# 3. 配置集群

##### 3.1. 集群规划配置

  ![img_2.png](img_2.png)

##### 3.2. 






