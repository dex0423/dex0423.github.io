---
layout:     post
title:      ETL方法论：数据清洗
subtitle:   
date:       2022-01-27
author:     dex0423
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - 数仓
---


# 1. 数据清洗价值

##### 1.1. 数据流转过程

![]({{site.baseurl}}/img-post/etl-6-1.png)

##### 1.2. 源数据存在的问题

业务部门的数据往往是有很多问题的，存在大量问题，

- 数据本身问题：
  - 建表命名不规范
  - 字段属性错误
  - 数据值录入错误
  - 数据丢失
  - 数据重复
- 设计问题：
  - 数据不规范
  - 格式不统一
- 需要看到数据，才能知道如何制定规则；
- 有些数据，需要跨部门联合检验；

##### 1.3. 数据清洗的价值

- 确保数据的可用性
  - 真实
  - 有效
  - 规范
  - 统一
- 反向提升业务系统
  - 及时发现问题，并提交给来源系统做问题定位和整改，进而提升数据的可用性。

# 2. 数据校验

##### 2.1. 规性校验：基于规则
- 身份证合规
  - 行政区划、年份、月份、日期，需要符合规则
- 手机号合规
  - 位数
  - 号段
  - 事实表多表联合校验
- 邮箱地址合规
- 组织结构代码证合规
- 地址信息合规
- 一致性校验：
  - 属性一致性
  - 关系一致性

##### 2.2. 值域范围校验
  - 一般需要与维度表联合校验
  - 比如：
    - ID：某订单数据的商品ID为10001，但商品表ID字段值域范围最大是10000，超出了值域范围；
    - 性别：性别为 3，不在性别维度表 0（未填写）、1（男）、2（女）值域范围内；

##### 2.3. 数据格式较严
  - 比如：
    - 概率：概率值应该为 0~1，但实际确实 2、3、4 等；
    - 年龄：应该为整数值，并且在0~120之间。

##### 2.4， 空值校验
  - 非空字段
    - 比如：年龄、性别
  - 可为空字段
    - 比如：爱好

##### 2.5. 准确性校验
  - 比如：
    - 业务人员一、二级部门归属；

##### 2.6. 完整性校验
  - 比如：
    - 地址信息缺失街道门牌号

# 3. 数据清洗规则

##### 3.1. 数据过滤

- 基于样本数据过滤
  - 主要用于处理垃圾数据：
  - 比如：垃圾样本库
    - 垃圾短信
    - 垃圾邮件
- 基于业务规则过滤
  - 比如：无效日志
    - 网络攻击
    - 爬虫

##### 3.2. 数据去重

- 全业务字段重复
  - 一般出现在数据同步过程中，
  - 比如同步任务异常、或者 kafka 同步的数据本身就存在重复；
  - 需要设定唯一主键，防止出现重复。
- 业务规则重复
  - 根绝业务规则判定需要保留的数据
  - 比如：一个身份证号对应多个用户ID

##### 3.3. 格式转换

- 日期时间
- 全角半角
- 大小写
- 经纬度
- 设备 Mac 地址

##### 3.4. 数据置空
- 置空不合规字段：
  - 比如：
    - 在BI分析时，尽管有部分字段不合规，但字段值置空并不影响数据分析，所以就可以将数据置空