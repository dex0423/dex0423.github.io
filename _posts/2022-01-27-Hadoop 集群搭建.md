---
layout:     post
title:      Hadoop 集群搭建过程示例
subtitle:   以 Windows + CentOS 7 虚拟机为例
date:       2022-01-27
author:     dex0423
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - 数仓
---

# 1. 集群配置

##### 1.1. 获取 root 权限
```aidl
su
# 输入密码
```

##### 1.2. 修改主机名

- hadoop-1
```aidl
hostnamectl set-hostname hadoop-1
```
- hadoop-2
```aidl
hostnamectl set-hostname hadoop-2
```
- hadoop-3
```aidl
hostnamectl set-hostname hadoop-3
```

##### 1.3. 修改网卡配置

```aidl
cd /etc/sysconfig/network-scripts/
vim ifcfg-ens33
```

```aidl
PROXY_METHOD="nc"
BROWSER_ONLY="nc"
BOOTPROTO="static"
NAME="ens33"
DEVICE="ens33"
ONBOOT="yes"
IPADDR=192.168.1.101
NETMASK=255.255.255.0
GATEWAY=192.168.1.254
DNS1=192.168.1.254      # 注意：这里不配置会导致虚拟机上不了网
```

```aidl
# 启动生效
systemctl restart network
```

##### 1.4. 主机名与IP映射

```aidl
vi /etc/hosts
192.168.1.101 master
192.168.1.102 slave1
192.168.1.103 slave2
```

##### 1.5. 配置SSH免密登录

>此处只在 master 上配置免密登录 slave

```aidl
#进入用户目录
cd /home/用户名

#生成密钥,回车即可
ssh-keygen -t rsa

#到.ssh目录下
cd .ssh/

#到.ssh目录下
cd /root/.ssh/

#将id_rsa.pub添加到authorized_keys目录
cp id_rsa.pub authorized_keys

ssh-copy-id -i slave1

ssh-copy-id -i slave2
```

##### 1.6. NAT配置

![]({{site.baseurl}}/img-post/hadoop-1.png)

![]({{site.baseurl}}/img-post/hadoop-2.png)

![]({{site.baseurl}}/img-post/hadoop-3.png)



# 2. 安装 Hadoop

##### 2.1. 配置 jdk 

- 删除原生 java，注意 master 和 slave 机器都要删掉
```aidl
# 查找jdk 安装位置
rpm -qa | grep java
javapackages-tools-3.4.1-11.el7.noarch
java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64
tzdata-java-2020a-1.el7.noarch
java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64
java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64
python-javapackages-3.4.1-11.el7.noarch
java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64

# 删除
rpm -e --nodeps javapackages-tools-3.4.1-11.el7.noarch
rpm -e --nodeps java-1.8.0-openjdk-headless-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps tzdata-java-2020a-1.el7.noarch
rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.261-2.6.22.2.el7_8.x86_64
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.262.b10-1.el7.x86_64
rpm -e --nodeps python-javapackages-3.4.1-11.el7.noarch
rpm -e --nodeps java-1.7.0-openjdk-1.7.0.261-2.6.22.2.el7_8.x86_64

# 检查有没有删除
java -version
bash: java: command not found...
```

- 在 home 目录下，解压缩 jdk-8u162-linux-x64.tar.gz 文件，并保存到 `jdk1.8.0` 文件目录下。

```aidl
tar -zxvf jdk-8u162-linux-x64.tar.gz jdk1.8.0
```

- 配置环境变量
```aidl
export JAVA_HOME=/home/用户名/jdk1.8.0
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin

```

- 环境变量生效
```aidl
source .bashrc
```

- 检查安装情况
```aidl
java -version

java version "1.8.0_162"
Java(TM) SE Runtime Environment (build 1.8.0_162-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)
```

- 复制文件到子节点
```aidl
scp -r /home/用户名/jdk1.8.0 用户名@slave1:/home/用户名/

scp -r /home/用户名/jdk1.8.0 用户名@slave2:/home/用户名/
```

# 安装配置Hadoop




- 交易数据： 
  结构化数据，一般存在 MySQL 数据库；
  需要同步到 HDFS，以进行用户行为分析和算法推荐；
  同步工作，一般由 Sqoop 或者 DataX 完成；
  需要 MaxWell 实时监控；

> MySQL 建表一般都是小表，数据冗余小，磁盘利用率高。但这种情况并不适合大数据分析，因为做 MapReduce 的时候，大量的跨表join会导致 MySQL 运行极度缓慢，查询操作性能极差。

- 用户行为数据：
  日志文件（半结构化数据），一般存在本地磁盘； 
  Flume 同步到 HDFS；
  HDFS 上的数据由 Hive 来进行分析；

# 数仓的应用

##### 报表系统

主要用于 BI 建设。

##### 用户画像

##### 推荐系统

##### 机器学习

##### 风控系统



# 数仓项目需求分析

##### 数据采集

- 用户行为数据采集平台搭建
- 业务数据采集平台搭建 

##### 数据建模

- 关系模型
- 维度模型

##### 业务分析

- 统计报表（可视化大屏）
- 即席查询

> 注意：Hive 导出的数据一般最终还是要存到 MySQL，因为 BI 团队可能不会用 Hive，同时 MySQL 作为通用数据库可以方便的提供统一接口。

##### 集群性能监控

- 异常告警

##### 元数据管理

- 表名 + 字段名
- 大数据分层，结果字段是由哪些字段计算得出来的，不同层、不同表的字段之间关系是什么样的。

##### 质量监控


##### Apache 版本对应情况

- JAVA： 1.8
- Hadoop： 3.1.3
- Hive： 3.1.2
- Flume： 1.9.0
- Zookeeper： 3.5.7
- Kafka： 2.4.1
- DataX： 3.0
- MaxWell： 1.29.2


![]({{site.baseurl}}/img-post/fwq-1-1.jpg)

